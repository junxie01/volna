//
// auto-generated by op2.py
//

//user function
inline void NumericalFluxes(const float *maxEdgeEigenvalues0,
          const float *maxEdgeEigenvalues1, 
          const float *maxEdgeEigenvalues2, 
          const float *EdgeVolumes0,
          const float *EdgeVolumes1,
          const float *EdgeVolumes2,
          const float *cellVolumes, //OP_READ
            float *zeroInit, float *minTimeStep ) //OP_MIN
{
  float local = 0.0f;
  local += maxEdgeEigenvalues0[0] * EdgeVolumes0[0];
  local += maxEdgeEigenvalues1[0] * EdgeVolumes1[0];
  local += maxEdgeEigenvalues2[0] * EdgeVolumes2[0];
  zeroInit[0] = 0.0f;
  zeroInit[1] = 0.0f;
  zeroInit[2] = 0.0f;
  zeroInit[3] = 0.0f;

  *minTimeStep = MIN(*minTimeStep, 2.0f * cellVolumes[0] / local);
}
#ifdef VECTORIZE
//user function -- modified for vectorisation
void NumericalFluxes_vec( const float maxEdgeEigenvalues0[*][SIMD_VEC], const float maxEdgeEigenvalues1[*][SIMD_VEC], const float maxEdgeEigenvalues2[*][SIMD_VEC], const float EdgeVolumes0[*][SIMD_VEC], const float EdgeVolumes1[*][SIMD_VEC], const float EdgeVolumes2[*][SIMD_VEC], const float *cellVolumes, float *zeroInit, float *minTimeStep, int idx ) {
  float local = 0.0f;
  local += maxEdgeEigenvalues0[0][idx] * EdgeVolumes0[0][idx];
  local += maxEdgeEigenvalues1[0][idx] * EdgeVolumes1[0][idx];
  local += maxEdgeEigenvalues2[0][idx] * EdgeVolumes2[0][idx];
  zeroInit[0] = 0.0f;
  zeroInit[1] = 0.0f;
  zeroInit[2] = 0.0f;
  zeroInit[3] = 0.0f;

  *minTimeStep = MIN(*minTimeStep, 2.0f * cellVolumes[0] / local);
}
#endif

// host stub function
void op_par_loop_NumericalFluxes(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4,
  op_arg arg5,
  op_arg arg6,
  op_arg arg7,
  op_arg arg8){

  int nargs = 9;
  op_arg args[9];

  args[0] = arg0;
  args[1] = arg1;
  args[2] = arg2;
  args[3] = arg3;
  args[4] = arg4;
  args[5] = arg5;
  args[6] = arg6;
  args[7] = arg7;
  args[8] = arg8;
  //create aligned pointers for dats
  ALIGNED_float const float * __restrict__ ptr0 = (float *) arg0.data;
  __assume_aligned(ptr0,float_ALIGN);
  ALIGNED_float const float * __restrict__ ptr1 = (float *) arg1.data;
  __assume_aligned(ptr1,float_ALIGN);
  ALIGNED_float const float * __restrict__ ptr2 = (float *) arg2.data;
  __assume_aligned(ptr2,float_ALIGN);
  ALIGNED_float const float * __restrict__ ptr3 = (float *) arg3.data;
  __assume_aligned(ptr3,float_ALIGN);
  ALIGNED_float const float * __restrict__ ptr4 = (float *) arg4.data;
  __assume_aligned(ptr4,float_ALIGN);
  ALIGNED_float const float * __restrict__ ptr5 = (float *) arg5.data;
  __assume_aligned(ptr5,float_ALIGN);
  ALIGNED_float const float * __restrict__ ptr6 = (float *) arg6.data;
  __assume_aligned(ptr6,float_ALIGN);
  ALIGNED_float       float * __restrict__ ptr7 = (float *) arg7.data;
  __assume_aligned(ptr7,float_ALIGN);
  float arg8h = *(float *)arg8.data;

  // initialise timers
  double cpu_t1, cpu_t2, wall_t1, wall_t2;
  op_timing_realloc(8);
  op_timers_core(&cpu_t1, &wall_t1);

  int  ninds   = 2;
  int  inds[9] = {0,0,0,1,1,1,-1,-1,-1};

  if (OP_diags>2) {
    printf(" kernel routine with indirection: NumericalFluxes\n");
  }

  #ifdef OP_PART_SIZE_8
    int part_size = OP_PART_SIZE_8;
  #else
    int part_size = OP_part_size;
  #endif


  int set_size = op_mpi_halo_exchanges(set, nargs, args);

  if (set_size >0) {

    // get plan
    op_plan *Plan = op_plan_get_stage_upload(name,set,part_size,nargs,args,ninds,inds,OP_STAGE_ALL,0);

    // execute plan
    int block_offset = 0;
    for ( int col=0; col<Plan->ncolors; col++ ){
      if (col==Plan->ncolors_core) {
        op_mpi_wait_all(nargs, args);
      }
      int nblocks = Plan->ncolblk[col];

      #pragma omp parallel for reduction(min:arg8h)
      for ( int blockIdx=0; blockIdx<nblocks; blockIdx++ ){
        int blockId  = Plan->blkmap[blockIdx + block_offset];
        int nelem    = Plan->nelems[blockId];
        int offset_b = Plan->offset[blockId];
        #ifdef VECTORIZE
        float dat8[SIMD_VEC] = {-INFINITY};
        //peel left remainder
        for ( int n=offset_b; n<((offset_b-1)/SIMD_VEC+1)*SIMD_VEC; n++ ){
          int map0idx = arg0.map_data[n * arg0.map->dim + 0];
          int map1idx = arg0.map_data[n * arg0.map->dim + 1];
          int map2idx = arg0.map_data[n * arg0.map->dim + 2];

          NumericalFluxes(
            &(ptr0)[1 * map0idx],
            &(ptr1)[1 * map1idx],
            &(ptr2)[1 * map2idx],
            &(ptr3)[1 * map0idx],
            &(ptr4)[1 * map1idx],
            &(ptr5)[1 * map2idx],
            &(ptr6)[1 * n],
            &(ptr7)[4 * n],
            &arg8h);
        }
        #pragma novector
        for ( int n=((offset_b-1)/SIMD_VEC+1)*SIMD_VEC; n<((offset_b+nelem)/SIMD_VEC)*SIMD_VEC; n+=SIMD_VEC ){
          if (n+SIMD_VEC >= set->core_size) {
            op_mpi_wait_all(nargs, args);
          }
          ALIGNED_float float dat0[1][SIMD_VEC];
          ALIGNED_float float dat1[1][SIMD_VEC];
          ALIGNED_float float dat2[1][SIMD_VEC];
          ALIGNED_float float dat3[1][SIMD_VEC];
          ALIGNED_float float dat4[1][SIMD_VEC];
          ALIGNED_float float dat5[1][SIMD_VEC];
          #pragma omp simd aligned(ptr0,ptr1,ptr2,ptr3,ptr4,ptr5,ptr6,ptr7)
          for ( int i=0; i<SIMD_VEC; i++ ){
            int idx0_1 = 1 * arg0.map_data[(n+i) * arg0.map->dim + 0];
            int idx1_1 = 1 * arg0.map_data[(n+i) * arg0.map->dim + 1];
            int idx2_1 = 1 * arg0.map_data[(n+i) * arg0.map->dim + 2];
            int idx3_1 = 1 * arg0.map_data[(n+i) * arg0.map->dim + 0];
            int idx4_1 = 1 * arg0.map_data[(n+i) * arg0.map->dim + 1];
            int idx5_1 = 1 * arg0.map_data[(n+i) * arg0.map->dim + 2];

            dat0[0][i] = (ptr0)[idx0_1 + 0];

            dat1[0][i] = (ptr1)[idx1_1 + 0];

            dat2[0][i] = (ptr2)[idx2_1 + 0];

            dat3[0][i] = (ptr3)[idx3_1 + 0];

            dat4[0][i] = (ptr4)[idx4_1 + 0];

            dat5[0][i] = (ptr5)[idx5_1 + 0];

          }
          #pragma omp simd aligned(ptr0,ptr1,ptr2,ptr3,ptr4,ptr5,ptr6,ptr7)
          for ( int i=0; i<SIMD_VEC; i++ ){
            NumericalFluxes_vec(
              dat0,
              dat1,
              dat2,
              dat3,
              dat4,
              dat5,
              &(ptr6)[1 * (n+i)],
              &(ptr7)[4 * (n+i)],
              dat8,
              i);
          }
          for ( int i=0; i<SIMD_VEC; i++ ){

          }
          for ( int i=0; i<SIMD_VEC; i++ ){
            arg8h = MIN(arg8h,dat8[i]);
          }
        }

        //remainder
        for ( int n=((offset_b+nelem)/SIMD_VEC)*SIMD_VEC; n<offset_b+nelem; n++ ){
        #else
        #pragma omp simd aligned(ptr0,ptr1,ptr2,ptr3,ptr4,ptr5,ptr6,ptr7) reduction(min:arg8h)
        for ( int n=offset_b; n<offset_b+nelem; n++ ){
        #endif
          int map0idx = arg0.map_data[n * arg0.map->dim + 0];
          int map1idx = arg0.map_data[n * arg0.map->dim + 1];
          int map2idx = arg0.map_data[n * arg0.map->dim + 2];

          NumericalFluxes(
            &(ptr0)[1 * map0idx],
            &(ptr1)[1 * map1idx],
            &(ptr2)[1 * map2idx],
            &(ptr3)[1 * map0idx],
            &(ptr4)[1 * map1idx],
            &(ptr5)[1 * map2idx],
            &(ptr6)[1 * n],
            &(ptr7)[4 * n],
            &arg8h);
        }
      }
      block_offset += nblocks;
    }
  }

  if (set_size == 0 || set_size == set->core_size) {
    op_mpi_wait_all(nargs, args);
  }
  // combine reduction data
  *(float*)arg8.data = arg8h;
  op_mpi_reduce(&arg8,(float*)arg8.data);
  op_mpi_set_dirtybit(nargs, args);

  // update kernel record
  op_timers_core(&cpu_t2, &wall_t2);
  OP_kernels[8].name      = name;
  OP_kernels[8].count    += 1;
  OP_kernels[8].time     += wall_t2 - wall_t1;
  OP_kernels[8].transfer += (float)set->size * arg0.size;
  OP_kernels[8].transfer += (float)set->size * arg3.size;
  OP_kernels[8].transfer += (float)set->size * arg6.size;
  OP_kernels[8].transfer += (float)set->size * arg7.size;
  OP_kernels[8].transfer += (float)set->size * arg8.size * 2.0f;
  OP_kernels[8].transfer += (float)set->size * arg0.map->dim * 4.0f;
}
#undef VECTORIZE
